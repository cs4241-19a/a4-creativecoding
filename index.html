<!doctype html>
<html lang="en">
<head>
  <meta charset="UTF-8"/>
  <title>Assignment 4</title>
  <script src="https://threejsfundamentals.org/threejs/resources/threejs/r105/three.min.js"></script>
  <script src="https://cdn.bootcss.com/jquery/1.8.1/jquery.js"></script>
  <script src="OrbitControls.js"></script>
  <script type="text/javascript" src="dat.gui.js"></script>
</head>
<body>
  
  		<div id="dropbox" >
			<input type="file" name="" value="" id="musicFile" >
        <span>Click to upload or simply drag the file here</span>
		</div>

</body>

<script type="text/javascript">
  
var AudioContext = window.AudioContext || window.webkitAudioContext || window.mozAudioContext;

var audioContext = new AudioContext();
var dropbox, musicFile;

	dropbox = document.getElementById("dropbox");
	dropbox.addEventListener("dragenter", dragenter, false);
	dropbox.addEventListener("dragover", dragover, false);
	dropbox.addEventListener("dragleave", dragleave, false);
	dropbox.addEventListener("drop", drop, false);

	musicFile = document.getElementById("musicFile");
 	musicFile.addEventListener("change", readFile, false)

	// 目标进入drop区域
	function dragenter(e) {
		e.stopPropagation();
		e.preventDefault();
		dropbox.style.background = '#666'
	}
	// 目标位于drop区域上方
	function dragover(e) {
		e.stopPropagation();
		e.preventDefault();
	}
	// 目标离开drop区域
	function dragleave(e) {
		e.stopPropagation();
		e.preventDefault();
		dropbox.style.background = '#fbfbfb';
	}
	// 目标在drop区域被释放/放置（松开鼠标）
	function drop(e) {
		e.stopPropagation();
		e.preventDefault();
		dropbox.style.background = '#fbfbfb';
		handleFiles(e.dataTransfer.files[0]);
	}
	// 点击上传文件后的方法
	function readFile() {
		handleFiles($('#musicFile')[0].files[0]);
	}

	function handleFiles(f) {
  var file = f;//通过input上传的音频文件

  var fileReader = new FileReader();//使用FileReader异步读取文件
  fileReader.readAsArrayBuffer(file);//开始读取音频文件
  fileReader.onload = function(e) {//读取文件完成的回调
    //e.target.result 即为读取的音频文件（此文件为二进制文件）
    //下面开始解码操作 解码需要一定时间，这个时间应该让用户感知到
    var count = 0;

    var timer = setInterval(function(){
      count++;
    },1000)
    //开始解码，解码成功后执行回调函数 
    
    
    
    audioContext.decodeAudioData(e.target.result, function(buffer) {
      clearInterval(timer)

      // 创建AudioBufferSourceNode 用于播放解码出来的buffer的节点
      let audioBufferSourceNode = audioContext.createBufferSource();
      // 创建AnalyserNode 用于分析音频频谱的节点
      const analyser = audioContext.createAnalyser();
      //fftSize (Fast Fourier Transform) 是快速傅里叶变换，一般情况下是固定值2048。具体作用是什么我也不太清除，但是经过研究，这个值可以决定音频频谱的密集程度。值大了，频谱就松散，值小就密集。
      analyser.fftSize = 256 ;

      audioBufferSourceNode.connect(analyser);
      analyser.connect(audioContext.destination);
      console.log(audioContext.destination) 
      // 播放音频
      audioBufferSourceNode.buffer = buffer; //回调函数传入的参数 
      audioBufferSourceNode.start(); //部分浏览器是noteOn()函数，用法相同

      var dataArray = new Uint8Array(analyser.frequencyBinCount);
      console.log(dataArray)
      //alert(bufferLength);
      const step = Math.round(dataArray.length / appdata.length);
      function render() { 
          requestAnimationFrame(render);
         analyser.getByteFrequencyData(dataArray);

for(let j=0; j<appdata.length;j++){
     var value = dataArray[j * step] / 4;
            value = value < 1 ? 1 : value;
            appdata[j].scale.y = value;

  
  }
        renderer.render(scene, camera);
        }
// function render() {
//             requestAnimationFrame(render);
//           // while(i<5){
//           //   var cube3 = new THREE.Mesh(geometry, material); 
//           //   cube3.position.set(5*Math.random(),5*Math.random(),0);
//           //   scene.add(cube3);
//           //   i++;
//           // }
//           for(let j=0; j<appdata.length;j++){
//     appdata[j].rotation.x += 0.2*(Math.random());
//     appdata[j].rotation.y += -0.2*(Math.random());
  
//   }
          
  
//             renderer.render(scene, camera);
//         }
      render();
      
      //canvasCtx.clearRect(0, 0, 500, 500);
      // function draw() {
      //   drawVisual = requestAnimationFrame(draw);
      //   analyser.getByteFrequencyData(dataArray);
      //   canvasCtx.fillStyle = 'rgb(0, 0, 0)';
      //   canvasCtx.fillRect(0, 0, 500, 500);
      //   var barWidth = (500 / bufferLength) * 2.5;
      //   var barHeight;
      //   var x = 0;
      //   for(var i = 0; i < bufferLength; i++) {
      //     barHeight = dataArray[i];
      //     canvasCtx.fillStyle = 'rgb(' + (barHeight+100) + ',50,50)';
      //     canvasCtx.fillRect(x,500-barHeight/2,barWidth,barHeight/2);
      //     x += barWidth + 1;
      //   }
      // };
      // draw();
      
      
    });
    
    
  }
alert( 'Uploaded  (＾▽＾) ')
  } 
  
   var controls = new function(){
   this.colorR = 255-80;
   this.colorG = 50;
   this.colorB = 50;
 }
 
 var gui = new dat.GUI();
  gui.add(controls,'colorR',0,255);
  gui.add(controls,'colorG',0,255);
  gui.add(controls,'colorB',0,255);
  
  
  const appdata = []
      
      
        var scene = new THREE.Scene();
        var camera = new THREE.PerspectiveCamera(75, window.innerWidth/window.innerHeight, 0.1, 1000);
        var renderer = new THREE.WebGLRenderer();
        renderer.setSize(window.innerWidth, window.innerHeight);
        document.body.appendChild(renderer.domElement);


      function add(number){
         for (let i = 0; i < number; i++) {
           let r = controls.colorR-i*5;
	    		  let g = controls.colorG;
			      let b = controls.colorB;
			      let rgb = '#'+r.toString(16)+g.toString(16)+b.toString(16);
            let geometry = new THREE.BoxGeometry(0.5, 0.5, 0.5);
            let material = new THREE.MeshBasicMaterial({color: rgb});
            let cube = new THREE.Mesh(geometry, material); 
            cube.position.set(i - number/2, 0, 0);
            scene.add(cube);
            appdata.push(cube);
            
           
    }
        }
      add(30);
        camera.position.z = 50;
         

  
  

  

</script>
</html>